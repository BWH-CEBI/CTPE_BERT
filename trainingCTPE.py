# -*- coding: utf-8 -*-
"""Taxonomy_prepostArrc.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VksTXIaG_gQbuWfmoJKIPbzPdbtUF7DH
"""

# gpu_info = !nvidia-smi
# gpu_info = '\n'.join(gpu_info)
# if gpu_info.find('failed') >= 0:
#   print('Not connected to a GPU')
# else:
#   print(gpu_info)

import GPUtil
GPUtil.showUtilization()

from psutil import virtual_memory
ram_gb = virtual_memory().total / 1e9
print('Your runtime has {:.1f} gigabytes of available RAM\n'.format(ram_gb))

if ram_gb < 20:
  print('Not using a high-RAM runtime')
else:
  print('You are using a high-RAM runtime!')

import os
os.system("pip3 install transformers --use-feature=2020-resolver")
os.system("pip3 install torch")

#!pip install transformers --use-feature=2020-resolver
#!pip install torch

import pandas as pd
import numpy as np
import torch
import random
from sklearn.model_selection import KFold
from torch.utils.data import random_split, SubsetRandomSampler
from transformers import BertTokenizer
from torch.utils.data import TensorDataset
from transformers import AdamW, get_linear_schedule_with_warmup
from transformers import BertForSequenceClassification
from torch.utils.data import DataLoader, RandomSampler, SequentialSampler
from transformers import AdamW, get_linear_schedule_with_warmup
from sklearn.metrics import f1_score
from sklearn.metrics import PrecisionRecallDisplay
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import  confusion_matrix

def pr_rc_f1_score_func(preds, labels):
    preds_flat = np.argmax(preds, axis=1).flatten()
    labels_flat = labels.flatten()
    return precision_recall_fscore_support(labels_flat, preds_flat, average = 'weighted')

def evaluate(dataloader_val):
    model.eval()
    loss_val_total = 0
    predictions, true_vals = [], []
    for batch in tqdm(dataloader_val):
        batch = tuple(b.to(device) for b in batch)
        inputs = {'input_ids':      batch[0],
                  'attention_mask': batch[1],
                  'labels':         batch[2],
                 }
        with torch.no_grad():        
            outputs = model(**inputs)
        loss = outputs[0]
        logits = outputs[1]
        loss_val_total += loss.item()
        logits = logits.detach().cpu().numpy()
        label_ids = inputs['labels'].cpu().numpy()
        predictions.append(logits)
        true_vals.append(label_ids)
    loss_val_avg = loss_val_total/len(dataloader_val) 
    predictions = np.concatenate(predictions, axis=0)
    true_vals = np.concatenate(true_vals, axis=0)
    return loss_val_avg, predictions, true_vals

from tqdm import tqdm

tokenizer = BertTokenizer.from_pretrained(
    'bert-base-uncased',
    do_lower_case = True
)

import pandas as pd
df_raw = pd.read_excel('trainingsets/ctpe/ctpe-data-v2.xlsx')
#df_raw = pd.read_excel('ctpe-data.xlsx')
# df_raw.head()

df = df_raw[["Report Text","Annotation"]]
len(df)

# len(df['Annotation'])

#arrc = pd.read_csv('Post_ARRC_Data_final_42040.csv')
# arrc = pd.read_csv('neuro_reports.csv')
# arrc = pd.read_csv('Monthly Metrics_6-1-22-7-1-22.csv')
#arrc = pd.read_excel('Monthly Metrics 7-1-22-8-1-22.xlsx')

#arrc["Annotation"] = np.zeros(len(arrc))
#arrc.head(3)

#arrc['Annotation'] = 0
# arrc = arrc.rename(columns={"Report Text": "ReportText"})
#arrc = arrc.rename(columns={"final impression column": "ReportText"})

#arrc_new = arrc[["ReportText","Annotation"]]
#arrc_new.head(2)

#len(arrc_new)

#df = df.append(arrc_new, ignore_index=True)

len(df)

# arrc["ReportText"][9]
# df.ReportText.type()

#df = arrc_new

# df.ReportText=df.ReportText.astype(str)
df['Report Text']=df['Report Text'].astype(str)

df.head()

#a_string = "A string is more than its parts!"
matches = ["see finding", "see above", "per narrative",
           "see below"]


for i, row in df.iterrows():
    modified_text_train = row["Report Text"].lower().\
    replace("miscellaneous findings","miscellaneous").\
    replace("\r"," ").replace("\n"," ").\
    replace("end of impression","").\
    replace("end impression","").\
    replace("end of  impression","").\
    replace("창","").\
    replace("\t"," ")
    if any(x in modified_text_train for x in matches):
      df.at[i,'Modified_Text'] = modified_text_train.split("impression:")[0].\
      split("findings:")[-1].\
      split("interpreted by:")[0].\
      split("signed")[0].\
      split("reported by")[0].\
      split("attestation")[0].\
      split("i, the teaching")[0].\
      split("approved by attending:")[0].\
      split("non-critical results were")[0].\
      split("critical results were")[0].\
      split("the radiologist diagnostic certainty scale")[0]
    else:
      df.at[i,'Modified_Text'] = modified_text_train.split("impression:")[-1].\
      split("interpretation summary")[-1].\
      split("conclusion:")[-1].\
      split("interpretation:")[-1].\
      split("findings:")[-1].\
      split("interpreted by:")[0].\
      split("signed")[0].\
      split("reported by")[0].\
      split("attestation")[0].\
      split("i, the teaching")[0].\
      split("approved by attending:")[0].\
      split("non-critical results were")[0].\
      split("critical results were")[0].\
      split("the radiologist diagnostic certainty scale")[0]#.\
      #split("impression")[-1]
    
    #print(row['Modified_Text'])

#df_new = df[["Annotation", "Modified_Text"]]
#df_new["Modified_Text"][6473]

#for i, row in df.iterrows():
#    modified_addendum_train = row["ReportText"].lower().\
#    replace("\r"," ").replace("\n"," ").\
#    replace("창","").\
#    replace("\t"," ")
#    if "angiogram:" in modified_addendum_train:
#      if "addended" in modified_addendum_train:
#        df.at[i,'addendum'] = modified_addendum_train.split("addendum:")[-1].\
#        split("addended")[0]
#      elif "end of addendum" in modified_addendum_train:
#        df.at[i,'addendum'] = modified_addendum_train.split("addendum:")[-1].\
#        split("end of addendum")[0]
#      else:
#        df.at[i,'addendum'] = modified_addendum_train.split("addendum:")[-1].\
#        split("reason for exam")[0]

#for i, row in df.iterrows():
#    modified_addendum_train = row["ReportText"].lower().\
#    replace("\r"," ").replace("\n"," ").\
#    replace("창","").\
#    replace("\t"," ")
#    if "angiogram:" in modified_addendum_train:
#      if "angiogram" in modified_addendum_train:
#        df.at[i,'angiogram'] = modified_addendum_train.split("angiogram:")[-1].\
#        split("lungs:")[0]
#      # elif "end of addendum" in modified_addendum_train:
#      #   df.at[i,'addendum'] = modified_addendum_train.split("addendum:")[-1].\
#      #   split("end of addendum")[0]
#      # else:
#      #   df.at[i,'addendum'] = modified_addendum_train.split("addendum:")[-1].\
#      #   split("reason for exam")[0]

#df['Modified_Text'] =  df['Modified_Text']+ '-' + df['addendum']

df['Modified_Text_new'] = df['Modified_Text'].map(str) #+ '-' + df['addendum'].map(str)
#df['Modified_Text_new'] = df['Modified_Text'].map(str) + '-' + df['angiogram'].map(str)

#df.head()

#df["Modified_Text_new"][785]

df_new = df[["Annotation", "Modified_Text_new"]]

df_new = df_new.rename(columns={"Modified_Text_new": "Modified_Text"})

#df_new.tail(2)

# df.head()

# #a_string = "A string is more than its parts!"
# matches = ["See finding", "See above", "Per narrative",
#            "See below"]


# for i, row in df.iterrows():
#     modified_text_train = row["ReportText"].\
#     replace("miscellaneous findings","miscellaneous").\
#     replace("\r"," ").replace("\n"," ").\
#     replace("End of impression","").\
#     replace("End impression","").\
#     replace("End of  impression","").\
#     replace("창","").\
#     replace("\t"," ")
#     if any(x in modified_text_train for x in matches):
#       df.at[i,'Modified_Text'] = modified_text_train.split("IMPRESSION:")[0].\
#       split("FINDINGS:")[-1].\
#       split("Interpreted by:")[0].\
#       split("Signed")[0].\
#       split("Reported by")[0].\
#       split("ATTESTATION")[0].\
#       split("I, the teaching")[0].\
#       split("Approved by attending:")[0].\
#       split("Non-critical results were")[0].\
#       split("Critical results were")[0].\
#       split("The Radiologist Diagnostic Certainty Scale")[0]
#     else:
#       df.at[i,'Modified_Text'] = modified_text_train.split("IMPRESSION:")[-1].\
#       split("Interpretation summary")[-1].\
#       split("CONCLUSION:")[-1].\
#       split("interpretation:")[-1].\
#       split("FINDINGS:")[-1].\
#       split("Interpreted by:")[0].\
#       split("Signed")[0].\
#       split("Reported by")[0].\
#       split("ATTESTATION")[0].\
#       split("I, the teaching")[0].\
#       split("Approved by attending:")[0].\
#       split("Non-critical results were")[0].\
#       split("Critical results were")[0].\
#       split("The Radiologist Diagnostic Certainty Scale")[0].\
#       split("IMPRESSION")[-1]
    
#     #print(row['Modified_Text'])

# df_new = df[["Annotation", "Modified_Text"]]
# #df_new["Modified_Text"][6473]

# arrc['New_Modified_Text'] = df_new['Modified_Text']

#df_new['x'] = arrc['Accession'] + '-' + arrc['Modified_Text']

#df_new.head()

# arrc.head()

print(len(df_new['Annotation']))
print(len(df_new[df_new.Annotation == 0]))
print(len(df_new[df_new.Annotation == 1]))

df_new.index

#df["ReportText"][6473]

k_num = 5;
i=int(-1);


train_idx = range(len(df_raw['Annotation']))
#val_idx = range(len(df_raw['Annotation']),len(df_new['Annotation']))

#train_idx = range(4500)
#val_idx = range(4500,len(df_new['Annotation']))

df_new['data_type'] = ['not_set']*df_new.shape[0]
df_new.loc[train_idx, 'data_type'] = 'train'
#df_new.loc[val_idx, 'data_type'] = 'val'

encoded_data_train = tokenizer.batch_encode_plus(
  df_new[df_new.data_type == 'train'].Modified_Text.values,
  add_special_tokens = True,
  return_attention_mask = True,
  pad_to_max_length = True,
  max_length = 512,
  return_tensors = 'pt'
)

# encoded_data_val = tokenizer.batch_encode_plus(
#   df_new[df_new.data_type == 'val'].Modified_Text.values,
#   add_special_tokens = True,
#   return_attention_mask = True,
#   pad_to_max_length = True,
#   max_length = 512,
#   return_tensors = 'pt'
# )

input_ids_train = encoded_data_train['input_ids']
attention_mask_train = encoded_data_train['attention_mask']
labels_train = torch.tensor(df_new[df_new.data_type == 'train'].Annotation.values)

# input_ids_val = encoded_data_val['input_ids']
# attention_mask_val = encoded_data_val['attention_mask']
# labels_val = torch.tensor(df_new[df_new.data_type == 'val'].Annotation.values)

dataset_train = TensorDataset(input_ids_train,
                            attention_mask_train, labels_train)
# dataset_val = TensorDataset(input_ids_val,
#                             attention_mask_val, labels_val)

model = BertForSequenceClassification.from_pretrained(
  'bert-base-uncased',
  num_labels = 2,
  output_attentions = False,
  output_hidden_states = False
)
batch_size = 1

dataloader_train = DataLoader(
    dataset_train,
    sampler = RandomSampler(dataset_train),
    batch_size = batch_size
)

# dataloader_val = DataLoader(
#     dataset_val,
#     sampler = None,
#     batch_size = batch_size
# )
optimizer = AdamW(
  model.parameters(),
  lr = 1e-5, #2e-5 > 5e-5
  eps = 1e-8
)
epochs = 5

scheduler = get_linear_schedule_with_warmup(
    optimizer,
    num_warmup_steps = 0,
    num_training_steps = len(dataloader_train)*epochs
)
seed_val = 17
random.seed(seed_val)
np.random.seed(seed_val)
torch.manual_seed(seed_val)
torch.cuda.manual_seed_all(seed_val)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

for epoch in tqdm(range(1, epochs+1)):
  i=i+1;
  model.train() 
  loss_train_total = 0
    #progress_bar = tqdm(dataloader_train,
    #                   desc = 'Epoch {:id}'.format(epoch),
    #                   leave = False,
    #                   disable=False)
  progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)
  for batch in progress_bar:
      model.zero_grad()
        #batch = tuple(b.to(device) for b in batch)
      batch = tuple(b.to(device) for b in batch)
      inputs = {
          'input_ids'           :batch[0],
          'attention_mask'      :batch[1],
          'labels'              :batch[2]
      }
      outputs = model(**inputs)
      loss = outputs[0]
        #loss_train_total += loss.item()
      loss_train_total += loss.item()
      loss.backward() 
      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
      optimizer.step()
      scheduler.step()
      progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})
    #torch.save(model.state_dict(), f'Models/BERT_ft_epoch{epoch}.model')
  tqdm.write(f'\nEpoch: {epoch}')
  loss_train_avg = loss_train_total/len(dataloader_train)
  tqdm.write(f'Training loss: {loss_train_avg}')

range(len(df_raw['Annotation']),len(df_new['Annotation']))

# train_idx = range(len(df_raw['Annotation']))
# val_idx = range(len(df_raw['Annotation']),len(df_new['Annotation']))

# df_new['data_type'] = ['not_set']*df_new.shape[0]
# df_new.loc[train_idx, 'data_type'] = 'train'

# save model 
#os.makedirs("home/nooshin/projects/bert/finetuned_model/fu/trainingset-V3")
model.save_pretrained("finetuned_model/ctpe/trainingset-V2_modified")


